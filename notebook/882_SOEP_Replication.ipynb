{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 882 Replication with SOEP Data\n",
    "\n",
    "- SOEP from CPS, 2017\n",
    "- Estimation strategy from Flabbi 2010 \n",
    "\n",
    "- Need to add education and race for homogeneity in types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan.mccoy/anaconda3/lib/python3.6/site-packages/seaborn/apionly.py:6: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# General\n",
    "import pdb\n",
    "\n",
    "# Estimation\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "# import numdifftools as ndt\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn.apionly as sns\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data \n",
    "\n",
    "- SOEP (Germany) data on gender, wages, duration of unemployment\n",
    "- M: males\n",
    "- F: females\n",
    "- U: unemployed\n",
    "- E: employed \n",
    "- {M,F} X {E,U} = {males,females} X {employed, unemployed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_stata('../data/merged.dta') # 624,562\n",
    "df.columns = ['pid', 'year', 'inc_gro', 'inc_net', 'pos', 'emplsta', 'change', 'change_reason', 'dur', 'sex', 'age', 'hours', 'edu']\n",
    "\n",
    "# Only the year 2017\n",
    "df1 = df[df['year']==2017] # 31,630\n",
    "\n",
    "# Turning categorical into dummies\n",
    "df_sex = pd.get_dummies(df1, columns=['sex'])\n",
    "# 1 if man, 2 if woman. \n",
    "df_empl = pd.get_dummies(df_sex, columns=['emplsta'])\n",
    "# 5 if unemployed, 1 if full time\n",
    "df_edu = pd.get_dummies(df_empl, columns=['edu'])\n",
    "# 6 if bachelors, 7 if masters, 8 if doctorate\n",
    "\n",
    "# Keeping only the necessary variables \n",
    "df2 = df_edu[['inc_net', 'dur', 'age', 'sex_[2] weiblich', 'emplsta_[1] Voll erwerbstaetig', 'emplsta_[5] Nicht erwerbstaetig', 'hours', 'edu_[6] Bachelor s or equivalent level', 'edu_[7] Master s or equivalent level', 'edu_[8] Doctoral or equivalent level']]\n",
    "df2.columns = ['wage', 'dur', 'age', 'women', 'ft_empl', 'unempl', 'hours', 'college', 'masters', 'phd']\n",
    "\n",
    "# Using age for condition, then dropping age as a variable\n",
    "AGE_LOW = (df2['age']>29)\n",
    "AGE_HIGH = (df2['age']<56)\n",
    "AGE_COND = AGE_LOW & AGE_HIGH\n",
    "\n",
    "df3 = df2[AGE_COND==True] # 15,443\n",
    "\n",
    "# Creating condition for FT employment or unemployed only \n",
    "FT_COND = (df3['ft_empl']==1)\n",
    "UN_COND = (df3['unempl']==1)\n",
    "EMPL_COND = FT_COND | UN_COND\n",
    "\n",
    "df4 = df3[EMPL_COND==True] # 11,533\n",
    "\n",
    "# # Ensuring positive hours, wages for employed; positive unemployment duration for unemployed\n",
    "# POS_WAGE = (df4['wage']>0)\n",
    "# POS_HOURS = (df4['hours']>0)\n",
    "# EMPL = (df4['ft_empl']==1)\n",
    "# EMPLVAR_COND = POS_WAGE & POS_HOURS & EMPL\n",
    "\n",
    "# POS_DUR = (df4['dur']>0)\n",
    "# UNEMPL = (df4['unempl']==1)\n",
    "# UNEMPLVAR_COND = POS_DUR & UNEMPL\n",
    "\n",
    "# CONSIST_COND = EMPLVAR_COND | UNEMPLVAR_COND\n",
    "\n",
    "# df5 = df4[CONSIST_COND==True]\n",
    "\n",
    "# # Remove (-2) for \"does not apply\" in wage, hours for unemployed; dur for employed. Change wage to hourly for employed\n",
    "# if(UN_COND==True):\n",
    "#     df4.loc[df4['wage']<0, 'wage']=0\n",
    "#     df4.loc[df4['hours']<0, 'hours']=0\n",
    "# else:\n",
    "#     df4.loc[df4['dur']<0, 'dur']=0 \n",
    "#     df4['wage'] = df4['wage'] / df4['hours']\n",
    "\n",
    "# # Keeping only college or more educated \n",
    "# BS_COND = (df4['college']==1) \n",
    "# MS_COND = (df4['masters']==1) \n",
    "# PHD_COND = (df4['phd']==1)\n",
    "# EDU_COND = BS_COND | MS_COND | PHD_COND\n",
    "\n",
    "# df5 = df4[EDU_COND==True] #3,083\n",
    "\n",
    "\n",
    "# # Dropping unnecessary columns (age, unempl, edu, hours) and reorganizing to be consistent with CPS organization\n",
    "# df6 = df5[['dur', 'wage', 'empl', 'women']]\n",
    "\n",
    "# # Ensure not unemployment spell for employed\n",
    "# UNEMPL_COND = (df6['empl']==0)\n",
    "# POS_DUR_COND2 = (df6['dur']>0)\n",
    "# ZERO_DUR_COND = (df6['dur']==0)\n",
    "# POS_WAGE_COND = (df6['wage']>0)\n",
    "# EMPL_COND2 = (df6['empl']==1)\n",
    "# ZERO_WAGE_COND = (df6['wage']==0)\n",
    "# CONSIST_COND = (EMPL_COND2 & ZERO_DUR_COND & POS_WAGE_COND) | (UNEMPL_COND & POS_DUR_COND2 & ZERO_WAGE_COND)\n",
    "\n",
    "# df7 = df6[CONSIST_COND==True] #6910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>dur</th>\n",
       "      <th>age</th>\n",
       "      <th>women</th>\n",
       "      <th>ft_empl</th>\n",
       "      <th>unempl</th>\n",
       "      <th>hours</th>\n",
       "      <th>college</th>\n",
       "      <th>masters</th>\n",
       "      <th>phd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "      <td>8439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1637.395426</td>\n",
       "      <td>1.635618</td>\n",
       "      <td>42.824978</td>\n",
       "      <td>0.369831</td>\n",
       "      <td>0.707311</td>\n",
       "      <td>0.292689</td>\n",
       "      <td>27.070255</td>\n",
       "      <td>0.160683</td>\n",
       "      <td>0.084015</td>\n",
       "      <td>0.019078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1418.370184</td>\n",
       "      <td>3.489719</td>\n",
       "      <td>7.362296</td>\n",
       "      <td>0.482787</td>\n",
       "      <td>0.455024</td>\n",
       "      <td>0.455024</td>\n",
       "      <td>18.973017</td>\n",
       "      <td>0.367260</td>\n",
       "      <td>0.277426</td>\n",
       "      <td>0.136808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1670.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2400.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               wage          dur          age        women      ft_empl  \\\n",
       "count   8439.000000  8439.000000  8439.000000  8439.000000  8439.000000   \n",
       "mean    1637.395426     1.635618    42.824978     0.369831     0.707311   \n",
       "std     1418.370184     3.489719     7.362296     0.482787     0.455024   \n",
       "min       -2.000000    -1.000000    30.000000     0.000000     0.000000   \n",
       "25%       -2.000000     0.000000    37.000000     0.000000     0.000000   \n",
       "50%     1670.000000     0.400000    43.000000     0.000000     1.000000   \n",
       "75%     2400.000000     1.400000    49.000000     1.000000     1.000000   \n",
       "max    20000.000000    33.000000    55.000000     1.000000     1.000000   \n",
       "\n",
       "            unempl        hours      college      masters          phd  \n",
       "count  8439.000000  8439.000000  8439.000000  8439.000000  8439.000000  \n",
       "mean      0.292689    27.070255     0.160683     0.084015     0.019078  \n",
       "std       0.455024    18.973017     0.367260     0.277426     0.136808  \n",
       "min       0.000000    -2.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000    -2.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000    38.500000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000    40.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000    75.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change wage to be hourly \n",
    "\n",
    "# df7['wage'] = df7['wage'] / (40*4)\n",
    "\n",
    "df7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating naming conventions that are consistent with analysis from CPS data\n",
    "\n",
    "data = df7 \n",
    "\n",
    "M = data[data['women']==0] # men \n",
    "F = data[data['women']==1] # women \n",
    "U = data[data['empl']==0] # unemployed\n",
    "E = data[data['empl']==1] # employed\n",
    "\n",
    "ME = M[M['empl']==1] # employed men\n",
    "MU = M[M['empl']==0] # unemployed men\n",
    "FE = F[F['empl']==1] # employed women\n",
    "FU = F[F['empl']==0] # unemployed women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics, without trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'wage': ['mean', 'std', 'count'],\n",
    "    'dur': ['mean', 'std', 'count'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['women', 'empl']).agg(agg_dict).to_latex()) # by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.groupby(['empl']).agg(agg_dict).to_latex()) # all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "sns.distplot(ME['wage'], color='#4B9CD3', hist_kws={'alpha' : .3}, bins=50, ax=ax[0])\n",
    "sns.distplot(FE['wage'], color='#4B9CD3', hist_kws={'alpha' : .3}, bins=50, ax=ax[1])\n",
    "\n",
    "ax[0].legend(['Men'])\n",
    "ax[1].legend(['Women']) \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics, with trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Windsor for robustness check on trimming amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(ME['wage'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(ME['wage'],95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(FE['wage'], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(FE['wage'],95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only trim bottom \n",
    "\n",
    "# M_WAGE_COND = (data['wage'] > 7.786249999999999) #hard coded percentile so it does not continually update\n",
    "# M_COND = (data['women'] == 0)\n",
    "\n",
    "# F_WAGE_COND = (data['wage'] > 6.01125) #hard coded percentile so it does not continually update\n",
    "# F_COND = (data['women'] == 1)\n",
    "\n",
    "# DUR_COND = (data['dur'] > 0)\n",
    "\n",
    "# trim = data[ (M_COND & M_WAGE_COND) | (F_COND & F_WAGE_COND) | DUR_COND ]\n",
    "\n",
    "# M = trim[trim['women']==0] \n",
    "# F = trim[trim['women']==1] \n",
    "# U = trim[trim['empl']==0] \n",
    "# E = trim[trim['empl']==1] \n",
    "\n",
    "# ME = M[M['empl']==1] \n",
    "# MU = M[M['empl']==0] \n",
    "# FE = F[F['empl']==1] \n",
    "# FU = F[F['empl']==0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim both ends\n",
    "\n",
    "M_WAGE_COND_L = (data['wage'] > 7.786249999999999) #hard coded percentile so it does not continually update\n",
    "M_WAGE_COND_H = (data['wage'] < 35)\n",
    "M_COND = (data['women'] == 0)\n",
    "\n",
    "F_WAGE_COND_L = (data['wage'] > 6.01125) #hard coded percentile so it does not continually update\n",
    "F_WAGE_COND_H = (data['wage'] < 26.21249999999999)\n",
    "F_COND = (data['women'] == 1)\n",
    "\n",
    "DUR_COND = (data['empl'] == 0)\n",
    "\n",
    "trim = data[ (M_COND & M_WAGE_COND_L & M_WAGE_COND_H) | (F_COND & F_WAGE_COND_L & M_WAGE_COND_H) | DUR_COND ] #6,519\n",
    "\n",
    "M = trim[trim['women']==0] \n",
    "F = trim[trim['women']==1] \n",
    "U = trim[trim['empl']==0] \n",
    "E = trim[trim['empl']==1] \n",
    "\n",
    "ME = M[M['empl']==1] \n",
    "MU = M[M['empl']==0] \n",
    "FE = F[F['empl']==1] \n",
    "FU = F[F['empl']==0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trim.groupby(['women', 'empl']).agg(agg_dict).to_latex()) # by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trim.groupby(['empl']).agg(agg_dict).to_latex()) # all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures \n",
    "\n",
    "- Distribution of wages, men and women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "sns.distplot(ME['wage'], color='#4B9CD3', hist_kws={'alpha' : .3}, bins=50, ax=ax[0])\n",
    "sns.distplot(FE['wage'], color='#4B9CD3', hist_kws={'alpha' : .3}, bins=50, ax=ax[1])\n",
    "\n",
    "ax[0].legend(['Men'])\n",
    "ax[1].legend(['Women']) \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('./figures/fig1_2_SOEP.png', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ = 0.25530507424781373\n",
    "λ_M = 0.29441739346048834\n",
    "λ_F = 0.22246729559007514\n",
    "\n",
    "η = 0.15574303121563346\n",
    "η_M = 0.13822412838520579\n",
    "η_F = 0.20334901237530306\n",
    "\n",
    "μ = 15.922555\n",
    "μ_M = 16.959963\n",
    "μ_F= 13.678350\n",
    "\n",
    "σ = 6.040666\n",
    "σ_M = 6.094529\n",
    "σ_F = 5.266233\n",
    "\n",
    "p = 0.5\n",
    "d = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters without distributional assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstarM = min(ME['wage'])\n",
    "wstarF = min(FE['wage'])\n",
    "\n",
    "hM = MU['dur'].count()/sum(MU.values[:,0])\n",
    "hF = FU['dur'].count()/sum(FU.values[:,0])\n",
    "h = U['dur'].count()/sum(U.values[:,0])\n",
    "\n",
    "ηM = hM * (MU['dur'].count()/ME['empl'].count())\n",
    "ηF = hF * (FU['dur'].count()/FE['empl'].count())\n",
    "η = h * (U['dur'].count()/E['empl'].count())\n",
    "\n",
    "α = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstarF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accepted Wage Function and Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dens_accepted(wage: np.array, α: float, μ: float, σ: float, wstar: float):\n",
    "    \"\"\"\n",
    "    Calculates the density of accepted wages using the lognormal distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    l = (α*μ) + ((1-α)*wstar)\n",
    "    s = α * σ\n",
    "    shape = 1\n",
    "    \n",
    "    sf_in = (wstar - l)/s\n",
    "    \n",
    "    return stats.lognorm.pdf(wage, shape, l, s) / stats.lognorm.sf(sf_in, shape, l, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_accepted(FE['wage'],.5,13,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dens_accepted_prej(wage: np.array, α: float, μ: float, σ: float, wstar: float, d: float):\n",
    "    \"\"\"\n",
    "    Calculates the density of accepted wages when prejudice is present using the lognormal distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    l = (α*μ) + ((1-α)*wstar) - α*d\n",
    "    s = α * σ\n",
    "    shape = 1\n",
    "    \n",
    "    sf_in = (wstar - l)/s\n",
    "    \n",
    "    return stats.lognorm.pdf(wage,shape,l,s) / stats.lognorm.sf(wstar, shape, l, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambdaM(h: float, wstarM: float, α: float, μ: float, σ: float):\n",
    "    \"\"\"\n",
    "    Estimates lambda for men\n",
    "    \"\"\"\n",
    "    \n",
    "    l = (α*μ) + ((1-α)*wstarM)\n",
    "    s = α * σ\n",
    "    shape = 1\n",
    "    \n",
    "    sf_in = (wstarM-l)/s\n",
    "    \n",
    "    denom = stats.lognorm.sf(sf_in, shape, l, s)\n",
    "    \n",
    "    return h/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaM(hM, wstarM, α, μ_M, σ_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaM(h,wstarF,α,μ,σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambdaF(h: float, wstarF: float, α: float, μ: float, σ: float, p: float):\n",
    "    \"\"\"\n",
    "    Estimates lambda for women\n",
    "    \"\"\"\n",
    "    \n",
    "    l1 = (α*μ) + ((1-α)*wstarF)\n",
    "    l2 = (α*μ) + ((1-α)*wstarF) - α*d\n",
    "    s = α * σ\n",
    "    shape = 1\n",
    "    \n",
    "    sf_in1 = (wstarF-l1)/s\n",
    "    sf_in2 = (wstarF-l2)/s\n",
    "    \n",
    "    denom = (1-p)*stats.lognorm.sf(sf_in1, shape, l1, s) + p*stats.lognorm.sf(sf_in2, shape, l2, s)\n",
    "    \n",
    "    return h/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaF(hF, wstarF, α, μ_F, σ_F, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teststats (hess_inv : np.ndarray, lnL : float, nparams : int):\n",
    "    \"\"\"\n",
    "    Calculates the standard errors and p value from the LR tests\n",
    "    \"\"\"\n",
    "    se = np.sqrt(np.diag(hess_inv))\n",
    "    \n",
    "    loglik_H0 = lnL_6\n",
    "    \n",
    "    LR = 2 * (lnL - loglik_H0)\n",
    "    pval = stats.chi2.pdf(LR, nparams)\n",
    "    \n",
    "    return print('standard errors: ', se ,'. p = ', pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_6( params: list ):\n",
    "    \"\"\"\n",
    "    Calculates log likelihood with prejudice and productivity differences \n",
    "    \n",
    "    Estimation 6\n",
    "    \n",
    "    Parameters to estimate: \n",
    "        λM\n",
    "        λF\n",
    "        ηM\n",
    "        ηF\n",
    "        μM\n",
    "        σM\n",
    "        μF\n",
    "        σF\n",
    "        d\n",
    "        p\n",
    "    \"\"\"\n",
    "    \n",
    "    λM = np.exp(params[0])\n",
    "    λF = np.exp(params[1])\n",
    "    ηM = np.exp(params[2])\n",
    "    ηF = np.exp(params[3])\n",
    "    μM = params[4]\n",
    "    σM = np.exp(params[5])\n",
    "    μF = params[6]\n",
    "    σF = np.exp(params[7])\n",
    "    d = np.exp(params[8])\n",
    "    p = np.exp(params[9])/(1+np.exp(params[9]))\n",
    "\n",
    "#    pdb.set_trace()\n",
    "    \n",
    "    # Men's equations \n",
    "    λM = lambdaM(hM, wstarM, α, μM, σM)\n",
    "    \n",
    "    a = M['dur'].count() * np.log(hM/(hM+ηM))\n",
    "    b = MU['dur'].count() * np.log(ηM)\n",
    "    c = - hM * np.sum(MU.values[:,0])\n",
    "    e = np.sum( np.log( (1/α) * dens_accepted(ME['wage'], α, μM, σM, wstarM) ) )\n",
    "    \n",
    "    # Women's equations\n",
    "    λF = lambdaF(hF, wstarF, α, μM, σM, p)\n",
    "    \n",
    "    f = F['dur'].count() * np.log(hF/(hF+ηF))\n",
    "    g = FU['dur'].count() * np.log(ηF)\n",
    "    h = - hF * np.sum(FU.values[:,0])\n",
    "    \n",
    "    y = ((1-p)/α) * dens_accepted(FE['wage'], α, μF, σF, wstarF)\n",
    "    z = (p/α) * dens_accepted_prej(FE['wage'], α, μF, σF, wstarF, d)\n",
    "\n",
    "    i = np.sum( np.log( y + z ) )\n",
    "    \n",
    "    return (a + b + c + e + f + g + h + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on log-likelihood\n",
    "\n",
    "param6 = [λ_M, λ_F, η_M, η_F, μ_M, σ_M, μ_F, σ_F, d, p]\n",
    "\n",
    "b6_0 = np.log(param6[0])\n",
    "b6_1 = np.log(param6[1])\n",
    "b6_2 = np.log(param6[2])\n",
    "b6_3 = np.log(param6[3])\n",
    "b6_4 = param6[4]\n",
    "b6_5 = np.log(param6[5])\n",
    "b6_6 = param6[6]\n",
    "b6_7 = np.log(param6[7])\n",
    "b6_8 = np.log(param6[8])\n",
    "b6_9 = np.log(1)\n",
    "\n",
    "init6 = [b6_0, b6_1, b6_2, b6_3, b6_4, b6_5, b6_6, b6_7, b6_8, b6_9]\n",
    "\n",
    "print(loglik_6(init6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(init6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_6 = minimize(loglik_6, init6)\n",
    "\n",
    "est_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "λM_6 = np.exp(est_6.x[0])\n",
    "λF_6 = np.exp(est_6.x[1])\n",
    "ηM_6 = np.exp(est_6.x[2])\n",
    "ηF_6 = np.exp(est_6.x[3])\n",
    "μM_6 = est_6.x[4]\n",
    "σM_6 = np.exp(est_6.x[5])\n",
    "μF_6 = est_6.x[6]\n",
    "σF_6 = np.exp(est_6.x[7])\n",
    "d_6 = np.exp(est_6.x[8])\n",
    "p_6 = np.exp(est_6.x[9])/(1+np.exp(est_6.x[9]))\n",
    "\n",
    "print(λM_6, λF_6, ηM_6, ηF_6, μM_6, σM_6, μF_6, σF_6, d_6, p_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnL_6 = est_6.fun\n",
    "\n",
    "print(lnL_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_6 = teststats(est_6.hess_inv, lnL_6, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_3( params: list ):\n",
    "    \"\"\"\n",
    "    Calculates log likelihood with prejudice and productivity differences \n",
    "    \n",
    "    Estimation 3 (η and h not gender specific)\n",
    "    \n",
    "    Parameters to estimate: \n",
    "        λ \n",
    "        η\n",
    "        μM\n",
    "        σM\n",
    "        μF\n",
    "        σF\n",
    "        d\n",
    "        p\n",
    "    \"\"\"\n",
    "    \n",
    "    λM = np.exp(params[0]) #same lambda\n",
    "    λF = np.exp(params[0]) #same lambda\n",
    "    η = np.exp(params[1]) #same eta\n",
    "    μM = params[2]\n",
    "    σM = np.exp(params[3])\n",
    "    μF = params[4]\n",
    "    σF = np.exp(params[5])\n",
    "    d = np.exp(params[6])\n",
    "    p = np.exp(params[7])/(1+np.exp(params[7]))\n",
    "    \n",
    "    # Men's equations\n",
    "    λM = lambdaM(h, wstarM, α, μM, σM)\n",
    "    \n",
    "    a = M['dur'].count() * np.log(h/(h+η))\n",
    "    b = MU['dur'].count() * np.log(η)\n",
    "    c = - h * np.sum(MU.values[:,0])\n",
    "    e = np.sum( np.log( (1/α) * dens_accepted(ME['wage'], α, μM, σM, wstarM) ) )\n",
    "    \n",
    "    \n",
    "    # Women's equations\n",
    "    λF = lambdaF(h, wstarF, α, μM, σM, p)\n",
    "    \n",
    "    f = F['dur'].count() * np.log(h/(h+η))\n",
    "    g = FU['dur'].count() * np.log(η)\n",
    "    i = - h * np.sum(FU.values[:,0])\n",
    "    \n",
    "    y = ((1-p)/α) * dens_accepted(FE['wage'], α, μF, σF, wstarF)\n",
    "    z = (p/α) * dens_accepted_prej(FE['wage'], α, μF, σF, wstarF, d)\n",
    "\n",
    "    j = np.sum( np.log( y + z ) )\n",
    "    \n",
    "    \n",
    "    return a + b + c + e + f + g + i + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on log-likelihood\n",
    "\n",
    "param3 = [λ, η, μ_M, σ_M, μ_F, σ_F, d, p]\n",
    "\n",
    "b3_0 = np.log(param3[0])\n",
    "b3_1 = np.log(param3[1])\n",
    "b3_2 = param3[2]\n",
    "b3_3 = np.log(param3[3])\n",
    "b3_4 = param3[4]\n",
    "b3_5 = np.log(param3[5])\n",
    "b3_6 = np.log(param3[6])\n",
    "b3_7 = np.log(1)\n",
    "\n",
    "init3 = [b3_0, b3_1, b3_2, b3_3, b3_4, b3_5, b3_6, b3_7]\n",
    "\n",
    "print(loglik_3(init3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_3 = minimize(loglik_3, init3)\n",
    "\n",
    "est_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "λ_3 = np.exp(est_3.x[0])\n",
    "η_3 = np.exp(est_3.x[1])\n",
    "μM_3 = est_3.x[2]\n",
    "σM_3 = np.exp(est_3.x[3])\n",
    "μF_3 = est_3.x[4]\n",
    "σF_3 = np.exp(est_3.x[5])\n",
    "d_3 = np.exp(est_3.x[6])\n",
    "p_3 = np.exp(est_3.x[7])/(1+np.exp(est_3.x[7]))\n",
    "\n",
    "print(λ_3, η_3, μM_3, σM_3, μF_3, σF_3, d_3, p_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnL_3 = est_3.fun\n",
    "\n",
    "print(lnL_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_3 = teststats(est_3.hess_inv, lnL_3, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_5( params: list ):\n",
    "    \"\"\"\n",
    "    Calculates log likelihood with prejudice, no productivity differences. \n",
    "    \n",
    "    Estimation 5 (ηM, ηF, hM, hF)\n",
    "    \n",
    "    Parameters to estimate: \n",
    "        λM # see fxn elsewhere\n",
    "        λF # see fxn elsewhere\n",
    "        μ\n",
    "        σ\n",
    "        p\n",
    "        d\n",
    "    \"\"\"\n",
    "\n",
    "    λM = np.exp(params[0])\n",
    "    λF = np.exp(params[1])\n",
    "    ηM = np.exp(params[2])\n",
    "    ηF = np.exp(params[3])\n",
    "    μ = params[4]\n",
    "    σ = np.exp(params[5])\n",
    "    d = np.exp(params[6])\n",
    "    p = np.exp(params[7])/(1+np.exp(params[7]))\n",
    "    \n",
    "    # Men's equations \n",
    "    λM = lambdaM(hM, wstarM, α, μ, σ)\n",
    "    \n",
    "    a = M['dur'].count() * np.log(hM/(hM+ηM))\n",
    "    b = MU['dur'].count() * np.log(ηM)\n",
    "    c = - hM * np.sum(MU.values[:,0])\n",
    "    e = np.sum( np.log( (1/α) * dens_accepted(ME['wage'], α, μ, σ, wstarM) ) )\n",
    "    \n",
    "    \n",
    "    # Women's equations\n",
    "    λF = lambdaF(hF, wstarF, α, μ, σ, p)\n",
    "    \n",
    "    f = F['dur'].count() * np.log(hF/(hF+ηF))\n",
    "    g = FU['dur'].count() * np.log(ηF)\n",
    "    h = - hF * np.sum(FU.values[:,0])\n",
    "    \n",
    "    y = ((1-p)/α) * dens_accepted(FE['wage'], α, μ, σ, wstarF)\n",
    "    z = (p/α) * dens_accepted_prej(FE['wage'], α, μ, σ, wstarF, d)\n",
    "\n",
    "    i = np.sum( np.log( y + z ) )\n",
    "    \n",
    "    \n",
    "    return a + b + c + e + f + g + h + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on log-likelihood\n",
    "\n",
    "param5 = [λ_M, λ_F, η_M, η_F, μ, σ, d, p]\n",
    "\n",
    "b5_0 = np.log(param6[0])\n",
    "b5_1 = np.log(param6[1])\n",
    "b5_2 = np.log(param6[2])\n",
    "b5_3 = np.log(param6[3])\n",
    "b5_4 = param6[4]\n",
    "b5_5 = np.log(param6[5])\n",
    "b5_6 = np.log(param6[6])\n",
    "b5_7 = np.log(1)\n",
    "\n",
    "init5 = [b5_0, b5_1, b5_2, b5_3, b5_4, b5_5, b5_6, b5_7]\n",
    "\n",
    "print(loglik_5(init5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_5 = minimize(loglik_5, init5)\n",
    "\n",
    "est_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "λM_5 = np.exp(est_5.x[0])\n",
    "λF_5 = np.exp(est_5.x[1])\n",
    "ηM_5 = np.exp(est_5.x[2])\n",
    "ηF_5 = np.exp(est_5.x[3])\n",
    "μ_5 = est_5.x[4]\n",
    "σ_5 = np.exp(est_5.x[5])\n",
    "d_5 = np.exp(est_5.x[6])\n",
    "p_5 = np.exp(est_5.x[7])/(1+np.exp(est_5.x[7]))\n",
    "\n",
    "print(λM_5, λF_5, ηM_5, ηF_5, μ_5, σ_5, d_5, p_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnL_5 = est_5.fun\n",
    "\n",
    "print(lnL_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_5 = teststats(est_5.hess_inv, lnL_5, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_2( params: list ):\n",
    "    \"\"\"\n",
    "    Calculates log likelihood with prejudice, no productivity differences. \n",
    "    \n",
    "    Estimation 2 (η and h not gender specific)\n",
    "    \n",
    "    Parameters to estimate: \n",
    "        λ # see fxn elsewhere\n",
    "        μ\n",
    "        σ\n",
    "        p\n",
    "        d\n",
    "    \"\"\"\n",
    "    \n",
    "    λM = np.exp(params[0])\n",
    "    λF = np.exp(params[0])\n",
    "    η = np.exp(params[1])\n",
    "    μ = params[2]\n",
    "    σ = np.exp(params[3])\n",
    "    d = np.exp(params[4])\n",
    "    p = np.exp(params[5])/(1+np.exp(params[5]))\n",
    "\n",
    "    \n",
    "    # Men's equations \n",
    "    λM = lambdaM(h, wstarM, α, μ, σ)\n",
    "    \n",
    "    a = M['dur'].count() * np.log(h/(h+η))\n",
    "    b = MU['dur'].count() * np.log(η)\n",
    "    c = - h * np.sum(MU.values[:,0])\n",
    "    e = np.sum( np.log( (1/α) * dens_accepted(ME['wage'], α, μ, σ, wstarM) ) )\n",
    "    \n",
    "    \n",
    "    # Women's equations\n",
    "    λF = lambdaF(h, wstarF, α, μ, σ, p)\n",
    "    \n",
    "    f = F['dur'].count() * np.log(h/(h+η))\n",
    "    g = FU['dur'].count() * np.log(η)\n",
    "    i = - h * np.sum(FU.values[:,0])\n",
    "    \n",
    "    y = ((1-p)/α) * dens_accepted(FE['wage'], α, μ, σ, wstarF)\n",
    "    z = (p/α) * dens_accepted_prej(FE['wage'], α, μ, σ, wstarF, d)\n",
    "\n",
    "    j = np.sum( np.log( y + z ) )\n",
    "    \n",
    "    \n",
    "    return a + b + c + e + f + g + i + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on log-likelihood\n",
    "\n",
    "param2 = [λ, η, μ, σ, d, p]\n",
    "\n",
    "b2_0 = np.log(param2[0])\n",
    "b2_1 = np.log(param2[1])\n",
    "b2_2 = param2[2]\n",
    "b2_3 = np.log(param2[3])\n",
    "b2_4 = np.log(param2[4])\n",
    "b2_5 = np.log(1)\n",
    "\n",
    "init2 = [b2_0, b2_1, b2_2, b2_3, b2_4, b2_5]\n",
    "\n",
    "print(loglik_2(init2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_2 = minimize(loglik_2, init2)\n",
    "\n",
    "est_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "λ_2 = np.exp(est_2.x[0])\n",
    "η_2 = np.exp(est_2.x[1])\n",
    "μ_2 = est_2.x[2]\n",
    "σ_2 = np.exp(est_2.x[3])\n",
    "d_2 = np.exp(est_2.x[4])\n",
    "p_2 = np.exp(est_2.x[5])/(1+np.exp(est_2.x[5]))\n",
    "\n",
    "print(λ_2, η_2, μ_2, σ_2, d_2, p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnL_2 = est_2.fun\n",
    "\n",
    "print(lnL_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_2 = teststats(est_2.hess_inv, lnL_2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_4( params: list ):\n",
    "    \"\"\"\n",
    "    Calculates log likelihood with productivity differences, no prejudice\n",
    "    \n",
    "    Estimation 4 (ηM, ηF, hM, hF)\n",
    "    \n",
    "    Parameters to estimate: \n",
    "        λM # see fxn elsewhere\n",
    "        λF # see fxn elsewhere\n",
    "        μM\n",
    "        σM\n",
    "        μF\n",
    "        σF\n",
    "    \"\"\"\n",
    "\n",
    "    λM = np.exp(params[0])\n",
    "    λF = np.exp(params[1])\n",
    "    ηM = np.exp(params[2])\n",
    "    ηF = np.exp(params[3])\n",
    "    μM = params[4]\n",
    "    σM = np.exp(params[5])\n",
    "    μF = params[6]\n",
    "    σF = np.exp(params[6])\n",
    "    p = 0\n",
    "    \n",
    "    # Men's equations \n",
    "    λM = lambdaM(hM, wstarM, α, μM, σM)\n",
    "    \n",
    "    a = M['dur'].count() * np.log(hM/(hM+ηM))\n",
    "    b = MU['dur'].count() * np.log(ηM)\n",
    "    c = - hM * np.sum(MU.values[:,0])\n",
    "    e = np.sum( np.log( (1/α) * dens_accepted(ME['wage'], α, μM, σM, wstarM) ) )\n",
    "    \n",
    "    \n",
    "    # Women's equations\n",
    "    λF = lambdaF(hF, wstarF, α, μF, σF, p)\n",
    "    \n",
    "    f = F['dur'].count() * np.log(hF/(hF+ηF))\n",
    "    g = FU['dur'].count() * np.log(ηF)\n",
    "    h = - hF * np.sum(FU.values[:,0])\n",
    "    \n",
    "    y = (1/α) * dens_accepted(FE['wage'], α, μF, σF, wstarF)\n",
    "\n",
    "    i = np.sum( np.log( y ) )\n",
    "    \n",
    "    \n",
    "    return a + b + c + e + f + g + h + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on log-likelihood\n",
    "\n",
    "param4 = [λ_M, λ_F, η_M, η_F, μ_M, σ_M, μ_F, σ_F]\n",
    "\n",
    "b4_0 = np.log(param4[0])\n",
    "b4_1 = np.log(param4[1])\n",
    "b4_2 = np.log(param4[2])\n",
    "b4_3 = np.log(param4[3])\n",
    "b4_4 = param4[4]\n",
    "b4_5 = np.log(param4[5])\n",
    "b4_6 = param4[6]\n",
    "b4_7 = np.log(param4[7])\n",
    "\n",
    "init4 = [b4_0, b4_1, b4_2, b4_3, b4_4, b4_5, b4_6, b4_7]\n",
    "\n",
    "print(loglik_4(init4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_4 = minimize(loglik_4, init4)\n",
    "\n",
    "est_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "λM_4 = np.exp(est_4.x[0])\n",
    "λF_4 = np.exp(est_4.x[1])\n",
    "ηM_4 = np.exp(est_4.x[2])\n",
    "ηF_4 = np.exp(est_4.x[3])\n",
    "μM_4 = est_4.x[4]\n",
    "σM_4 = np.exp(est_4.x[5])\n",
    "μF_4 = est_4.x[6]\n",
    "σF_4 = np.exp(est_4.x[7])\n",
    "\n",
    "print(λM_4, λF_4, ηM_4, ηF_4, μM_4, σM_4, μF_4, σF_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnL_4 = est_4.fun\n",
    "\n",
    "print(lnL_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_4 = teststats(est_4.hess_inv, lnL_4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_1( params: list ):\n",
    "    \"\"\"\n",
    "    Calculates log likelihood with productivity differences, no prejudice\n",
    "    \n",
    "    Estimation 1 (η and h not gender specific)\n",
    "    \n",
    "    Parameters to estimate: \n",
    "        λ\n",
    "        μM\n",
    "        σM\n",
    "        μF\n",
    "        σF\n",
    "    \"\"\"\n",
    "\n",
    "    λM = np.exp(params[0]) #same lambda\n",
    "    λF = np.exp(params[0]) #same lambda\n",
    "    η = np.exp(params[1]) #same eta\n",
    "    μM = params[2]\n",
    "    σM = np.exp(params[3])\n",
    "    μF = params[4]\n",
    "    σF = np.exp(params[5])\n",
    "    p = 0\n",
    "    \n",
    "    # Men's equations \n",
    "    λM = lambdaM(h, wstarM, α, μM, σM)\n",
    "    \n",
    "    a = M['dur'].count() * np.log(h/(h+η))\n",
    "    b = MU['dur'].count() * np.log(η)\n",
    "    c = - h * np.sum(MU.values[:,0])\n",
    "    e = np.sum( np.log( (1/α) * dens_accepted(ME['wage'], α, μM, σM, wstarM) ) )\n",
    "    \n",
    "    \n",
    "    # Women's equations\n",
    "    λF = lambdaF(h, wstarF, α, μF, σF, p)\n",
    "    \n",
    "    f = F['dur'].count() * np.log(h/(h+η))\n",
    "    g = FU['dur'].count() * np.log(η)\n",
    "    i = - h * np.sum(FU.values[:,0])\n",
    "    \n",
    "    y = (1/α) * dens_accepted(FE['wage'], α, μF, σF, wstarF)\n",
    "\n",
    "    j = np.sum( np.log( y ) )\n",
    "    \n",
    "    \n",
    "    return a + b + c + e + f + g + i + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on log-likelihood\n",
    "\n",
    "param1 = [λ, η, μ_M, σ_M, μ_F, σ_F]\n",
    "\n",
    "b1_0 = np.log(param1[0])\n",
    "b1_1 = np.log(param1[1])\n",
    "b1_2 = param1[2]\n",
    "b1_3 = np.log(param1[3])\n",
    "b1_4 = param1[4]\n",
    "b1_5 = np.log(param1[5])\n",
    "\n",
    "init1 = [b1_0, b1_1, b1_2, b1_3, b1_4, b1_5]\n",
    "\n",
    "print(loglik_1(init1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_1 = minimize(loglik_1, init1)\n",
    "\n",
    "est_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "λ_1 = np.exp(est_1.x[0])\n",
    "η_1 = np.exp(est_1.x[1])\n",
    "μM_1 = est_1.x[2]\n",
    "σM_1 = np.exp(est_1.x[3])\n",
    "μF_1 = est_1.x[4]\n",
    "σF_1 = np.exp(est_1.x[5])\n",
    "\n",
    "print(λ_1, η_1, μM_1, σM_1, μF_1, σF_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnL_1 = est_1.fun\n",
    "\n",
    "print(lnL_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_1 = teststats(est_1.hess_inv, lnL_1, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
